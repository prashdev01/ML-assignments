{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Polynomial functions are often used as kernel functions in machine learning algorithms, particularly in Support Vector Machines (SVMs). In SVMs, kernel functions are used to implicitly map the input data into a higher-dimensional space where it may be linearly separable. Polynomial kernels are a type of kernel function that computes the dot product between two vectors in the transformed space, often using polynomial functions. This transformation allows SVMs to find nonlinear decision boundaries by mapping the input features into a higher-dimensional space where the data might be separable by a hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "dataset = load_iris()\n",
    "x = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# split the dataset into train test split \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size=0.2,random_state=42)\n",
    "\n",
    "# process the data \n",
    "scaler =  StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# create an instance of the svc with poly kernel\n",
    "svm_classifier = SVC(kernel='poly',degree=3) # degree represent the degree of polynomial\n",
    "\n",
    "# train the classifier on the training data\n",
    "svm_classifier.fit(X_train_scaled,Y_train)\n",
    "\n",
    "# use the trained classifier to predict the labeles of the testing data \n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(Y_test,y_pred)\n",
    "print(accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "increasing the value of the epsilon in support vector regrassion(SVR ) typically result in  a larger margin of tolerance around the predicted values. cosequntly, it can lead to fewer support vectors being selected ,as the model becomes more tolerant errors beyond the margin, conversly decreasing epsilon can result in a smaller margin of tolerance, potentially leading to support vector beaing selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kernel function: The choice of kernel function (e.g., linear, polynomial, radial basis function) determines how the input space is transformed. Different kernel functions may capture different types of relationships in the data.\n",
    "\n",
    "* C parameter: This parameter trades off the flatness of the hyperplane against the amount of training error allowed. Increasing C allows the model to fit the training data more closely, potentially leading to overfitting, while decreasing it encourages a wider margin and may improve generalization.\n",
    "\n",
    "* Epsilon parameter: Epsilon determines the width of the margin around the predicted values within which no penalty is associated with errors. Increasing epsilon increases the margin of tolerance, potentially reducing the number of support vectors.\n",
    "\n",
    "* Gamma parameter: This parameter defines how far the influence of a single training example reaches, with low values meaning far and high values meaning close. High gamma values can lead to overfitting, while low values can lead to underfitting.\n",
    "\n",
    "- Examples of when you might want to increase or decrease each parameter:\n",
    "\n",
    " - Kernel function: Experiment with different kernel functions based on the nonlinearity of your data.\n",
    " - C parameter: Increase C when you have a small number of noisy observations, decrease it when you want a smoother decision boundary.\n",
    " - Epsilon parameter: Increase epsilon when you have noisy data or want a wider margin, decrease it when you want to enforce a stricter tolerance for errors.\n",
    " - Gamma parameter: Increase gamma when you have complex data with intricate relationships, decrease it when you want simpler models or have a large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q5. Assignment:**\n",
    "* Import the necessary libraries and load the dataseg\n",
    "* Split the dataset into training and testing setZ\n",
    "* Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "* Create an instance of the SVC classifier and train it on the training datW\n",
    "* hse the trained classifier to predict the labels of the testing datW\n",
    "* Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,precision, recall, F1-scoreK\n",
    "* Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "* Train the tuned classifier on the entire dataseg\n",
    "* Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best Hyperparameters: {'C': 10, 'degree': 2, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Accuray 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split ,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# load the data\n",
    "data = load_iris()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "# split the data into train test data \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# preprocess the data using standerscaler technique \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid ={\n",
    "    'C': [0.1,1,10],\n",
    "    'kernel' : ['linear','poly','rbf'],\n",
    "    'gamma' : [0.1,1,10],\n",
    "    'degree' : [2,3,4],\n",
    "}\n",
    "\n",
    "# instance of svc classifier \n",
    "svm_classifier =  SVC()\n",
    "grid_serach = GridSearchCV(svm_classifier,param_grid=param_grid,cv=5)\n",
    "grid_serach.fit(X_train_scaled,Y_train)\n",
    "\n",
    "# get the best hyper paramaeters\n",
    "best_params = grid_serach.best_params_\n",
    "print('best Hyperparameters:',best_params)\n",
    "\n",
    "# train and tuned the classifier on the entire dataset \n",
    "best_svm_classifier = SVC(**best_params)\n",
    "best_svm_classifier.fit(X_train_scaled,Y_train)\n",
    "\n",
    "# save the trained classifier for future use\n",
    "with open('svm_classifier.pkl','wb') as f:\n",
    "    pickle.dump(best_svm_classifier,f)\n",
    "    \n",
    "# Evalute the performance of the classifier\n",
    "y_pred = best_svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(Y_test,y_pred)\n",
    "print(\"Accuray\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
